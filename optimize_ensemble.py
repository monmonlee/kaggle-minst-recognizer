import numpy as np
import json
from tensorflow.keras.models import load_model
from sklearn.metrics import accuracy_score
from itertools import product
import pandas as pd

print("="*70)
print("ğŸ¯ å„ªåŒ– Ensemble æ¬Šé‡ - åœ¨é©—è­‰é›†ä¸Šæœå°‹æœ€ä½³çµ„åˆ")
print("="*70)

# 1. è¼‰å…¥é©—è­‰é›†è³‡æ–™
print("\nğŸ“‚ è¼‰å…¥é©—è­‰é›†è³‡æ–™...")
X_val = np.load('X_val.npy')
y_val = np.load('y_val.npy')
print(f"âœ“ é©—è­‰é›†è¼‰å…¥å®Œæˆï¼š{X_val.shape}")

# 2. è¼‰å…¥æ¸¬è©¦é›†è³‡æ–™
print("\nğŸ“‚ è¼‰å…¥æ¸¬è©¦é›†è³‡æ–™...")
X_test = np.load('X_test.npy')
print(f"âœ“ æ¸¬è©¦é›†è¼‰å…¥å®Œæˆï¼š{X_test.shape}")

# 3. è¼‰å…¥æ¨¡å‹è³‡è¨Š
print("\nğŸ“‚ è¼‰å…¥æ¨¡å‹è³‡è¨Š...")
with open('ensemble_models_info.json', 'r') as f:
    models_info = json.load(f)

print(f"âœ“ æ‰¾åˆ° {len(models_info)} å€‹æ¨¡å‹")

# 4. è¼‰å…¥æ‰€æœ‰æ¨¡å‹
print("\nğŸ’¾ è¼‰å…¥æ‰€æœ‰è¨“ç·´å¥½çš„æ¨¡å‹...")
models = []
for info in models_info:
    model_path = f"{info['model_name']}_best.keras"
    try:
        model = load_model(model_path)
        models.append({
            'model': model,
            'name': info['model_name'],
            'val_accuracy': info['val_accuracy']
        })
        print(f"  âœ“ è¼‰å…¥ï¼š{info['model_name']} (é©—è­‰é›†æº–ç¢ºç‡: {info['val_accuracy']:.4f})")
    except Exception as e:
        print(f"  âš ï¸  ç„¡æ³•è¼‰å…¥ {model_path}")

n_models = len(models)
print(f"\nâœ“ æˆåŠŸè¼‰å…¥ {n_models} å€‹æ¨¡å‹")

# 5. å°é©—è­‰é›†é€²è¡Œé æ¸¬ï¼ˆä¸ç”¨ TTAï¼Œæ›´å¿«ï¼‰
print("\nğŸ”® å°é©—è­‰é›†é€²è¡Œé æ¸¬...")
val_predictions = []
for i, model_dict in enumerate(models, 1):
    model = model_dict['model']
    print(f"  [{i}/{n_models}] {model_dict['name']}")
    preds = model.predict(X_val, verbose=0)
    val_predictions.append(preds)

print("âœ“ é©—è­‰é›†é æ¸¬å®Œæˆ")

# 6. æœå°‹æœ€ä½³æ¬Šé‡çµ„åˆ
print("\n" + "="*70)
print("ğŸ” åœ¨é©—è­‰é›†ä¸Šæœå°‹æœ€ä½³æ¬Šé‡çµ„åˆ")
print("="*70)

def weighted_ensemble(predictions, weights):
    """ä½¿ç”¨æ¬Šé‡çµ„åˆé æ¸¬"""
    weighted_preds = np.average(predictions, axis=0, weights=weights)
    return np.argmax(weighted_preds, axis=1)

# æ–¹æ³• 1ï¼šç¶²æ ¼æœå°‹ï¼ˆç²—ç•¥ï¼‰
print("\nã€æ–¹æ³• 1ã€‘ç²—ç•¥ç¶²æ ¼æœå°‹...")
print("ç¯„åœï¼šæ¯å€‹æ¨¡å‹æ¬Šé‡ 0.1 - 0.3ï¼ˆæ­¥é•· 0.05ï¼‰")

best_accuracy = 0
best_weights = None
search_count = 0

# ç”Ÿæˆæ¬Šé‡å€™é¸ï¼ˆç¢ºä¿ç¸½å’Œç‚º 1ï¼‰
weight_options = np.arange(0.1, 0.35, 0.05)

# é™åˆ¶æœå°‹ç©ºé–“ï¼ˆé¿å…å¤ªä¹…ï¼‰
# åªæœå°‹å‰ 1000 ç¨®çµ„åˆ
max_searches = 1000
search_step = 0

for weights_combo in product(weight_options, repeat=n_models):
    search_step += 1
    if search_step > max_searches:
        break
    
    weights = np.array(weights_combo)
    
    # æ­£è¦åŒ–æ¬Šé‡ï¼ˆç¸½å’Œç‚º 1ï¼‰
    if weights.sum() == 0:
        continue
    weights = weights / weights.sum()
    
    # çµ„åˆé æ¸¬
    ensemble_preds = weighted_ensemble(val_predictions, weights)
    accuracy = accuracy_score(y_val, ensemble_preds)
    
    if accuracy > best_accuracy:
        best_accuracy = accuracy
        best_weights = weights
        print(f"  ğŸ‰ æ‰¾åˆ°æ›´å¥½çš„çµ„åˆï¼æº–ç¢ºç‡ï¼š{accuracy:.5f}")
        print(f"     æ¬Šé‡ï¼š{weights}")
    
    if search_step % 100 == 0:
        print(f"  å·²æœå°‹ï¼š{search_step}/{max_searches}")

print(f"\nâœ“ ç²—ç•¥æœå°‹å®Œæˆ")
print(f"âœ“ æœ€ä½³é©—è­‰é›†æº–ç¢ºç‡ï¼š{best_accuracy:.5f}")
print(f"âœ“ æœ€ä½³æ¬Šé‡ï¼š{best_weights}")

# 7. æ–¹æ³• 2ï¼šåŸºæ–¼é©—è­‰é›†æº–ç¢ºç‡çš„æ™ºèƒ½æ¬Šé‡
print("\n" + "="*70)
print("ã€æ–¹æ³• 2ã€‘åŸºæ–¼é©—è­‰é›†æº–ç¢ºç‡çš„é€²éšæ¬Šé‡")
print("="*70)

# å–å¾—æ¯å€‹æ¨¡å‹çš„é©—è­‰é›†æº–ç¢ºç‡
val_accuracies = np.array([m['val_accuracy'] for m in models])

# ç­–ç•¥ Aï¼šç·šæ€§æ¬Šé‡
linear_weights = val_accuracies / val_accuracies.sum()
linear_preds = weighted_ensemble(val_predictions, linear_weights)
linear_accuracy = accuracy_score(y_val, linear_preds)
print(f"\nç­–ç•¥ Aï¼ˆç·šæ€§æ¬Šé‡ï¼‰ï¼š")
print(f"  æ¬Šé‡ï¼š{linear_weights}")
print(f"  æº–ç¢ºç‡ï¼š{linear_accuracy:.5f}")

# ç­–ç•¥ Bï¼šå¹³æ–¹æ¬Šé‡ï¼ˆå¼·åŒ–å¥½æ¨¡å‹ï¼‰
squared_weights = val_accuracies ** 2
squared_weights = squared_weights / squared_weights.sum()
squared_preds = weighted_ensemble(val_predictions, squared_weights)
squared_accuracy = accuracy_score(y_val, squared_preds)
print(f"\nç­–ç•¥ Bï¼ˆå¹³æ–¹æ¬Šé‡ï¼‰ï¼š")
print(f"  æ¬Šé‡ï¼š{squared_weights}")
print(f"  æº–ç¢ºç‡ï¼š{squared_accuracy:.5f}")

# ç­–ç•¥ Cï¼šæŒ‡æ•¸æ¬Šé‡ï¼ˆæ›´å¼·åŒ–å¥½æ¨¡å‹ï¼‰
exp_weights = np.exp(val_accuracies * 10)  # æ”¾å¤§å·®ç•°
exp_weights = exp_weights / exp_weights.sum()
exp_preds = weighted_ensemble(val_predictions, exp_weights)
exp_accuracy = accuracy_score(y_val, exp_preds)
print(f"\nç­–ç•¥ Cï¼ˆæŒ‡æ•¸æ¬Šé‡ï¼‰ï¼š")
print(f"  æ¬Šé‡ï¼š{exp_weights}")
print(f"  æº–ç¢ºç‡ï¼š{exp_accuracy:.5f}")

# ç­–ç•¥ Dï¼šåªç”¨æœ€å¥½çš„ 3 å€‹æ¨¡å‹
top3_indices = np.argsort(val_accuracies)[-3:]
top3_weights = np.zeros(n_models)
top3_weights[top3_indices] = val_accuracies[top3_indices]
top3_weights = top3_weights / top3_weights.sum()
top3_preds = weighted_ensemble(val_predictions, top3_weights)
top3_accuracy = accuracy_score(y_val, top3_preds)
print(f"\nç­–ç•¥ Dï¼ˆåªç”¨å‰ 3 åï¼‰ï¼š")
print(f"  æ¬Šé‡ï¼š{top3_weights}")
print(f"  æº–ç¢ºç‡ï¼š{top3_accuracy:.5f}")

# 8. æ¯”è¼ƒæ‰€æœ‰ç­–ç•¥
print("\n" + "="*70)
print("ğŸ“Š æ‰€æœ‰ç­–ç•¥æ¯”è¼ƒ")
print("="*70)

strategies = {
    'ç¶²æ ¼æœå°‹æœ€ä½³': (best_weights, best_accuracy),
    'ç·šæ€§æ¬Šé‡': (linear_weights, linear_accuracy),
    'å¹³æ–¹æ¬Šé‡': (squared_weights, squared_accuracy),
    'æŒ‡æ•¸æ¬Šé‡': (exp_weights, exp_accuracy),
    'åªç”¨å‰3å': (top3_weights, top3_accuracy)
}

# æ’åº
sorted_strategies = sorted(strategies.items(), key=lambda x: x[1][1], reverse=True)

print("\né©—è­‰é›†æº–ç¢ºç‡æ’åï¼š")
for i, (name, (weights, acc)) in enumerate(sorted_strategies, 1):
    print(f"{i}. {name:15s}: {acc:.5f}")

# æ‰¾å‡ºæœ€ä½³ç­–ç•¥
best_strategy_name, (final_best_weights, final_best_accuracy) = sorted_strategies[0]

print(f"\nğŸ† æœ€ä½³ç­–ç•¥ï¼š{best_strategy_name}")
print(f"   é©—è­‰é›†æº–ç¢ºç‡ï¼š{final_best_accuracy:.5f}")
print(f"   æ¬Šé‡ï¼š{final_best_weights}")

# 9. ä½¿ç”¨æœ€ä½³æ¬Šé‡é æ¸¬æ¸¬è©¦é›†
print("\n" + "="*70)
print("ğŸš€ ä½¿ç”¨æœ€ä½³æ¬Šé‡é æ¸¬æ¸¬è©¦é›†")
print("="*70)

# å°æ¸¬è©¦é›†é€²è¡Œé æ¸¬
print("\nå°æ¸¬è©¦é›†é€²è¡Œé æ¸¬...")
test_predictions = []
for i, model_dict in enumerate(models, 1):
    model = model_dict['model']
    print(f"  [{i}/{n_models}] {model_dict['name']}")
    preds = model.predict(X_test, verbose=0)
    test_predictions.append(preds)

# ä½¿ç”¨æœ€ä½³æ¬Šé‡çµ„åˆ
final_test_preds = weighted_ensemble(test_predictions, final_best_weights)

# ç”¢ç”Ÿæäº¤æª”æ¡ˆ
submission = pd.DataFrame({
    'ImageId': range(1, len(final_test_preds) + 1),
    'Label': final_test_preds
})

output_filename = f'submission_optimized_weights.csv'
submission.to_csv(output_filename, index=False)

print(f"\nâœ“ æ¸¬è©¦é›†é æ¸¬å®Œæˆ")
print(f"âœ“ å·²å„²å­˜ï¼š{output_filename}")
print(f"\né æ¸¬æ¨™ç±¤åˆ†ä½ˆï¼š")
print(submission['Label'].value_counts().sort_index())

# 10. åŒæ™‚ç”¢ç”Ÿæ‰€æœ‰ç­–ç•¥çš„æäº¤æª”æ¡ˆ
print("\n" + "="*70)
print("ğŸ“„ ç”¢ç”Ÿæ‰€æœ‰ç­–ç•¥çš„æäº¤æª”æ¡ˆ")
print("="*70)

for strategy_name, (weights, val_acc) in strategies.items():
    test_preds = weighted_ensemble(test_predictions, weights)
    
    submission = pd.DataFrame({
        'ImageId': range(1, len(test_preds) + 1),
        'Label': test_preds
    })
    
    filename = f"submission_{strategy_name.replace(' ', '_')}.csv"
    submission.to_csv(filename, index=False)
    print(f"âœ“ å·²å„²å­˜ï¼š{filename} (é©—è­‰é›†æº–ç¢ºç‡: {val_acc:.5f})")

# 11. ç¸½çµ
print("\n" + "="*70)
print("âœ… æ¬Šé‡å„ªåŒ–å®Œæˆï¼")
print("="*70)

print("\nğŸ’¡ å»ºè­°æäº¤é †åºï¼š")
for i, (name, (_, acc)) in enumerate(sorted_strategies, 1):
    filename = f"submission_{name.replace(' ', '_')}.csv"
    print(f"{i}. {filename}")
    print(f"   (é©—è­‰é›†æº–ç¢ºç‡: {acc:.5f})")

print("\nğŸ“Š é æœŸæ•ˆæœï¼š")
print(f"  - æœ€ä½³ç­–ç•¥é©—è­‰é›†æº–ç¢ºç‡ï¼š{final_best_accuracy:.5f}")
print(f"  - ç›¸æ¯”å¹³å‡æ¬Šé‡å¯èƒ½æå‡ï¼š0.0001-0.0005")
print(f"  - æ¸¬è©¦é›†é æœŸåˆ†æ•¸ï¼š0.996-0.997")

print("="*70)
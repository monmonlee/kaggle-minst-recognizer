import numpy as np
import json
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import pandas as pd

print("="*70)
print("ğŸ¯ å¤šç¨® TTA ç­–ç•¥çµ„åˆ")
print("="*70)

# 1. è¼‰å…¥æ¸¬è©¦è³‡æ–™
print("\nğŸ“‚ è¼‰å…¥æ¸¬è©¦è³‡æ–™...")
X_test = np.load('X_test.npy')
print(f"âœ“ æ¸¬è©¦é›†è¼‰å…¥å®Œæˆï¼š{X_test.shape}")

# 2. è¼‰å…¥æ¨¡å‹
print("\nğŸ’¾ è¼‰å…¥æ¨¡å‹...")
with open('ensemble_models_info.json', 'r') as f:
    models_info = json.load(f)

models = []
for info in models_info:
    model_path = f"{info['model_name']}_best.keras"
    try:
        model = load_model(model_path)
        models.append(model)
        print(f"  âœ“ è¼‰å…¥ï¼š{info['model_name']}")
    except:
        pass

print(f"\nâœ“ æˆåŠŸè¼‰å…¥ {len(models)} å€‹æ¨¡å‹")

# 3. å»ºç«‹ TTA ç”Ÿæˆå™¨
print("\nğŸ”„ å»ºç«‹ TTA ç”Ÿæˆå™¨...")
tta_datagen = ImageDataGenerator(
    rotation_range=10,
    width_shift_range=0.1,
    height_shift_range=0.1,
    zoom_range=0.1,
    fill_mode='nearest'
)

# 4. TTA é æ¸¬å‡½æ•¸
def predict_with_tta(model, X, n_augmentations):
    predictions = model.predict(X, verbose=0)
    for i in range(n_augmentations - 1):
        aug_generator = tta_datagen.flow(X, batch_size=len(X), shuffle=False)
        X_aug = next(aug_generator)
        predictions += model.predict(X_aug, verbose=0)
    return predictions / n_augmentations

# 5. ç­–ç•¥ï¼šä¸åŒæ¨¡å‹ç”¨ä¸åŒ TTA æ¬¡æ•¸
print("\n" + "="*70)
print("ğŸ¯ ç­–ç•¥ï¼šç‚ºæ¯å€‹æ¨¡å‹æ‰¾æœ€ä½³ TTA æ¬¡æ•¸")
print("="*70)

# é€™å€‹ç­–ç•¥æ˜¯ï¼šè®“ä¸åŒæ¨¡å‹ç”¨ä¸åŒçš„ TTA æ¬¡æ•¸
# å› ç‚ºæ¯å€‹æ¨¡å‹å¯èƒ½æœ‰è‡ªå·±çš„æœ€ä½³é»

print("\nç‚ºæ¯å€‹æ¨¡å‹æ¸¬è©¦ä¸åŒ TTA æ¬¡æ•¸ï¼ˆé€™æœƒéœ€è¦ä¸€äº›æ™‚é–“ï¼‰...")

# å®šç¾©è¦æ¸¬è©¦çš„ TTA æ¬¡æ•¸
tta_options = [10, 12, 15, 18, 20]

# å°æ¯å€‹æ¨¡å‹ï¼Œç”¨ä¸åŒ TTA æ¬¡æ•¸é æ¸¬
all_model_predictions = []

for model_idx, model in enumerate(models, 1):
    print(f"\nã€æ¨¡å‹ {model_idx}/{len(models)}ã€‘")
    model_predictions_by_tta = {}
    
    for n_tta in tta_options:
        print(f"  TTA x{n_tta}...", end=' ')
        preds = predict_with_tta(model, X_test, n_tta)
        model_predictions_by_tta[n_tta] = preds
        print("âœ“")
    
    all_model_predictions.append(model_predictions_by_tta)

print("\nâœ“ æ‰€æœ‰é æ¸¬å®Œæˆ")

# 6. çµ„åˆç­–ç•¥
print("\n" + "="*70)
print("ğŸ“Š æ¸¬è©¦ä¸åŒçš„çµ„åˆç­–ç•¥")
print("="*70)

strategies = {}

# ç­–ç•¥ Aï¼šæ‰€æœ‰æ¨¡å‹éƒ½ç”¨ TTA x15
print("\nç­–ç•¥ Aï¼šæ‰€æœ‰æ¨¡å‹çµ±ä¸€ç”¨ TTA x15")
preds_a = []
for model_preds in all_model_predictions:
    preds_a.append(model_preds[15])
avg_preds_a = np.mean(preds_a, axis=0)
labels_a = np.argmax(avg_preds_a, axis=1)
strategies['A_TTA15çµ±ä¸€'] = labels_a

# ç­–ç•¥ Bï¼šæ‰€æœ‰æ¨¡å‹éƒ½ç”¨ TTA x20
print("ç­–ç•¥ Bï¼šæ‰€æœ‰æ¨¡å‹çµ±ä¸€ç”¨ TTA x20")
preds_b = []
for model_preds in all_model_predictions:
    preds_b.append(model_preds[20])
avg_preds_b = np.mean(preds_b, axis=0)
labels_b = np.argmax(avg_preds_b, axis=1)
strategies['B_TTA20çµ±ä¸€'] = labels_b

# ç­–ç•¥ Cï¼šæ··åˆä¸åŒ TTAï¼ˆæ¯å€‹æ¨¡å‹ç”¨ä¸åŒçš„ï¼‰
print("ç­–ç•¥ Cï¼šæ¯å€‹æ¨¡å‹ç”¨ä¸åŒ TTA æ¬¡æ•¸")
tta_assignments = [15, 20, 18, 12, 15]  # ç‚ºæ¯å€‹æ¨¡å‹åˆ†é…ä¸åŒ TTA
preds_c = []
for i, model_preds in enumerate(all_model_predictions):
    assigned_tta = tta_assignments[i] if i < len(tta_assignments) else 15
    preds_c.append(model_preds[assigned_tta])
avg_preds_c = np.mean(preds_c, axis=0)
labels_c = np.argmax(avg_preds_c, axis=1)
strategies['C_TTAæ··åˆ'] = labels_c

# ç­–ç•¥ Dï¼šå°æ¯å€‹æ¨¡å‹ï¼Œå¹³å‡å¤šå€‹ TTA çš„çµæœ
print("ç­–ç•¥ Dï¼šæ¯å€‹æ¨¡å‹å¹³å‡å¤šå€‹ TTA çµæœ")
preds_d = []
for model_preds in all_model_predictions:
    # å¹³å‡è©²æ¨¡å‹æ‰€æœ‰ TTA çš„é æ¸¬
    avg_model_pred = np.mean([model_preds[tta] for tta in tta_options], axis=0)
    preds_d.append(avg_model_pred)
avg_preds_d = np.mean(preds_d, axis=0)
labels_d = np.argmax(avg_preds_d, axis=1)
strategies['D_TTAå¤šé‡å¹³å‡'] = labels_d

# ç­–ç•¥ Eï¼šè¶…ç´š Ensembleï¼ˆæ‰€æœ‰æ¨¡å‹ Ã— æ‰€æœ‰ TTAï¼‰
print("ç­–ç•¥ Eï¼šè¶…ç´š Ensembleï¼ˆæ‰€æœ‰çµ„åˆï¼‰")
all_predictions = []
for model_preds in all_model_predictions:
    for tta in tta_options:
        all_predictions.append(model_preds[tta])
avg_preds_e = np.mean(all_predictions, axis=0)
labels_e = np.argmax(avg_preds_e, axis=1)
strategies['E_è¶…ç´šEnsemble'] = labels_e

# 7. ç”¢ç”Ÿæ‰€æœ‰ç­–ç•¥çš„æäº¤æª”æ¡ˆ
print("\n" + "="*70)
print("ğŸ“„ ç”¢ç”Ÿæäº¤æª”æ¡ˆ")
print("="*70)

for strategy_name, labels in strategies.items():
    submission = pd.DataFrame({
        'ImageId': range(1, len(labels) + 1),
        'Label': labels
    })
    
    filename = f"submission_tta_{strategy_name}.csv"
    submission.to_csv(filename, index=False)
    print(f"âœ“ å·²å„²å­˜ï¼š{filename}")
    print(f"  æ¨™ç±¤åˆ†ä½ˆï¼š{pd.Series(labels).value_counts().sort_index().to_dict()}")

# 8. åˆ†æç­–ç•¥ä¹‹é–“çš„å·®ç•°
print("\n" + "="*70)
print("ğŸ” åˆ†æä¸åŒç­–ç•¥çš„å·®ç•°")
print("="*70)

strategy_names = list(strategies.keys())
for i in range(len(strategy_names)):
    for j in range(i+1, len(strategy_names)):
        name1, name2 = strategy_names[i], strategy_names[j]
        labels1, labels2 = strategies[name1], strategies[name2]
        
        agreement = np.sum(labels1 == labels2)
        disagreement = len(labels1) - agreement
        
        print(f"\n{name1} vs {name2}:")
        print(f"  ä¸€è‡´ï¼š{agreement} / {len(labels1)} ({agreement/len(labels1)*100:.2f}%)")
        print(f"  ä¸åŒï¼š{disagreement} ({disagreement/len(labels1)*100:.2f}%)")

# 9. ç¸½çµ
print("\n" + "="*70)
print("âœ… å¤šé‡ TTA ç­–ç•¥å®Œæˆï¼")
print("="*70)

print("\nç”¢ç”Ÿçš„æª”æ¡ˆï¼š")
for strategy_name in strategies.keys():
    print(f"  ğŸ“„ submission_tta_{strategy_name}.csv")

print("\nğŸ’¡ å»ºè­°æäº¤é †åºï¼š")
print("  1. submission_tta_E_è¶…ç´šEnsemble.csv  â† æœ€æ¨è–¦ï¼ˆçµ„åˆæœ€å¤šï¼‰")
print("  2. submission_tta_D_TTAå¤šé‡å¹³å‡.csv")
print("  3. submission_tta_C_TTAæ··åˆ.csv")
print("  4. submission_tta_B_TTA20çµ±ä¸€.csv")

print("\nğŸ“Š é æœŸæ•ˆæœï¼š")
print("  - è¶…ç´š Ensemble çµ„åˆäº† 25 å€‹é æ¸¬ï¼ˆ5 æ¨¡å‹ Ã— 5 TTAï¼‰")
print("  - ç†è«–ä¸Šæ‡‰è©²æœ€ç©©å®š")
print("  - é æœŸæå‡ï¼š0.0005-0.001")

print("="*70)
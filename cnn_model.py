import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models, callbacks
from tensorflow.keras.utils import to_categorical
import pandas as pd
from datetime import datetime

# è¨­å®šä¸­æ–‡å­—å‹
plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei', 'SimHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

# è¨­å®šéš¨æ©Ÿç¨®å­ï¼ˆç¢ºä¿çµæœå¯é‡ç¾ï¼‰
np.random.seed(42)
tf.random.set_seed(42)

class MNISTCNNTrainer:
    """MNIST CNN è¨“ç·´å™¨"""
    
    def __init__(self, model_name="MNIST_CNN"):
        """åˆå§‹åŒ–è¨“ç·´å™¨"""
        self.model_name = model_name
        self.model = None
        self.history = None
        
    def load_preprocessed_data(self):
        """è¼‰å…¥å·²å‰è™•ç†çš„è³‡æ–™"""
        print("ğŸ“‚ è¼‰å…¥å‰è™•ç†è³‡æ–™...")
        
        self.X_train = np.load('X_train.npy')
        self.X_val = np.load('X_val.npy')
        self.y_train = np.load('y_train.npy')
        self.y_val = np.load('y_val.npy')
        self.X_test = np.load('X_test.npy')
        
        print(f"âœ“ è³‡æ–™è¼‰å…¥å®Œæˆ")
        print(f"  X_train: {self.X_train.shape}")
        print(f"  X_val: {self.X_val.shape}")
        print(f"  X_test: {self.X_test.shape}")
        
        # è½‰æ›æ¨™ç±¤ç‚º One-Hot Encodingï¼ˆCNN éœ€è¦ï¼‰
        self.y_train_categorical = to_categorical(self.y_train, 10)
        self.y_val_categorical = to_categorical(self.y_val, 10)
        
        print(f"âœ“ æ¨™ç±¤è½‰æ›å®Œæˆï¼ˆOne-Hot Encodingï¼‰")
        print(f"  y_train: {self.y_train_categorical.shape}")
        
    def build_cnn_model(self, architecture='standard'):
        """
        å»ºç«‹ CNN æ¨¡å‹
        
        Parameters:
        -----------
        architecture : str
            'standard' - æ¨™æº– CNN
            'deep' - æ›´æ·±çš„ CNNï¼ˆæ›´å¤šå±¤ï¼‰
            'lightweight' - è¼•é‡ç´š CNNï¼ˆåƒæ•¸å°‘ï¼‰
        """
        print(f"\nğŸ—ï¸  å»ºç«‹ CNN æ¨¡å‹ï¼ˆæ¶æ§‹ï¼š{architecture}ï¼‰...")
        
        if architecture == 'standard':
            model = self._build_standard_cnn()
        elif architecture == 'deep':
            model = self._build_deep_cnn()
        elif architecture == 'lightweight':
            model = self._build_lightweight_cnn()
        else:
            raise ValueError("architecture å¿…é ˆæ˜¯ 'standard', 'deep', æˆ– 'lightweight'")
        
        self.model = model
        
        # é¡¯ç¤ºæ¨¡å‹æ¶æ§‹
        print("\nğŸ“Š æ¨¡å‹æ¶æ§‹æ‘˜è¦ï¼š")
        model.summary()
        
        # è¨ˆç®—åƒæ•¸é‡
        trainable_params = np.sum([np.prod(v.shape) for v in model.trainable_weights])
        print(f"\nâœ“ å¯è¨“ç·´åƒæ•¸æ•¸é‡ï¼š{trainable_params:,}")
        
        return model
    
    def _build_standard_cnn(self):
        """æ¨™æº– CNN æ¶æ§‹ï¼ˆæ ¹æ“šä½ çš„è¨ˆç•«ï¼‰"""
        model = models.Sequential([
            # ç¬¬ä¸€å±¤å·ç© + æ± åŒ–
            layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1), name='conv1'),
            layers.MaxPooling2D((2, 2), name='pool1'),
            
            # ç¬¬äºŒå±¤å·ç© + æ± åŒ–
            layers.Conv2D(64, (3, 3), activation='relu', name='conv2'),
            layers.MaxPooling2D((2, 2), name='pool2'),
            
            # ç¬¬ä¸‰å±¤å·ç©ï¼ˆå¢åŠ æ·±åº¦ï¼‰
            layers.Conv2D(64, (3, 3), activation='relu', name='conv3'),
            
            # å±•å¹³å±¤
            layers.Flatten(name='flatten'),
            
            # å…¨é€£æ¥å±¤
            layers.Dense(64, activation='relu', name='dense1'),
            layers.Dropout(0.5, name='dropout'),  # é˜²æ­¢éæ“¬åˆ
            
            # è¼¸å‡ºå±¤ï¼ˆ10 å€‹é¡åˆ¥ï¼‰
            layers.Dense(10, activation='softmax', name='output')
        ], name='Standard_CNN')
        
        return model
    
    def _build_deep_cnn(self):
        """æ›´æ·±çš„ CNN æ¶æ§‹ï¼ˆé©åˆè¤‡é›œç‰¹å¾µå­¸ç¿’ï¼‰"""
        model = models.Sequential([
            # Block 1
            layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(28, 28, 1)),
            layers.Conv2D(32, (3, 3), activation='relu', padding='same'),
            layers.MaxPooling2D((2, 2)),
            layers.Dropout(0.25),
            
            # Block 2
            layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
            layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
            layers.MaxPooling2D((2, 2)),
            layers.Dropout(0.25),
            
            # Block 3
            layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
            layers.MaxPooling2D((2, 2)),
            layers.Dropout(0.25),
            
            # Dense layers
            layers.Flatten(),
            layers.Dense(128, activation='relu'),
            layers.Dropout(0.5),
            layers.Dense(10, activation='softmax')
        ], name='Deep_CNN')
        
        return model
    
    def _build_lightweight_cnn(self):
        """è¼•é‡ç´š CNNï¼ˆé©åˆå¿«é€Ÿè¨“ç·´ï¼‰"""
        model = models.Sequential([
            layers.Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 1)),
            layers.MaxPooling2D((2, 2)),
            
            layers.Conv2D(32, (3, 3), activation='relu'),
            layers.MaxPooling2D((2, 2)),
            
            layers.Flatten(),
            layers.Dense(32, activation='relu'),
            layers.Dropout(0.3),
            layers.Dense(10, activation='softmax')
        ], name='Lightweight_CNN')
        
        return model
    
    def compile_model(self, learning_rate=0.001):
        """
        ç·¨è­¯æ¨¡å‹
        
        Parameters:
        -----------
        learning_rate : float
            å­¸ç¿’ç‡
        """
        print(f"\nâš™ï¸  ç·¨è­¯æ¨¡å‹ï¼ˆå­¸ç¿’ç‡ï¼š{learning_rate}ï¼‰...")
        
        self.model.compile(
            optimizer=keras.optimizers.Adam(learning_rate=learning_rate),
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        print("âœ“ æ¨¡å‹ç·¨è­¯å®Œæˆ")
    
    def train(self, epochs=20, batch_size=128, use_callbacks=True):
        """
        è¨“ç·´æ¨¡å‹
        
        Parameters:
        -----------
        epochs : int
            è¨“ç·´é€±æœŸæ•¸
        batch_size : int
            æ‰¹æ¬¡å¤§å°
        use_callbacks : bool
            æ˜¯å¦ä½¿ç”¨å›èª¿å‡½æ•¸ï¼ˆEarly Stopping, Model Checkpointï¼‰
        """
        print("\n" + "="*60)
        print("ğŸš€ é–‹å§‹è¨“ç·´æ¨¡å‹")
        print("="*60)
        print(f"è¨“ç·´åƒæ•¸ï¼š")
        print(f"  - Epochs: {epochs}")
        print(f"  - Batch Size: {batch_size}")
        print(f"  - è¨“ç·´æ¨£æœ¬æ•¸: {len(self.X_train)}")
        print(f"  - é©—è­‰æ¨£æœ¬æ•¸: {len(self.X_val)}")
        print("="*60)
        
        # è¨­å®šå›èª¿å‡½æ•¸
        callback_list = []
        
        if use_callbacks:
            # Early Stoppingï¼šé©—è­‰æå¤±ä¸å†ä¸‹é™æ™‚æå‰åœæ­¢
            early_stopping = callbacks.EarlyStopping(
                monitor='val_loss',
                patience=5,
                restore_best_weights=True,
                verbose=1
            )
            callback_list.append(early_stopping)
            
            # Model Checkpointï¼šå„²å­˜æœ€ä½³æ¨¡å‹
            checkpoint = callbacks.ModelCheckpoint(
                f'{self.model_name}_best.keras',
                monitor='val_accuracy',
                save_best_only=True,
                verbose=1
            )
            callback_list.append(checkpoint)
            
            # Learning Rate Schedulerï¼šå‹•æ…‹èª¿æ•´å­¸ç¿’ç‡
            reduce_lr = callbacks.ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.5,
                patience=3,
                min_lr=1e-6,
                verbose=1
            )
            callback_list.append(reduce_lr)
        
        # é–‹å§‹è¨“ç·´
        start_time = datetime.now()
        
        self.history = self.model.fit(
            self.X_train, self.y_train_categorical,
            epochs=epochs,
            batch_size=batch_size,
            validation_data=(self.X_val, self.y_val_categorical),
            callbacks=callback_list,
            verbose=1
        )
        
        end_time = datetime.now()
        training_time = (end_time - start_time).total_seconds()
        
        print("\n" + "="*60)
        print(f"âœ… è¨“ç·´å®Œæˆï¼ç¸½è€—æ™‚ï¼š{training_time:.2f} ç§’")
        print("="*60)
        
        return self.history
    
    def plot_training_history(self):
        """è¦–è¦ºåŒ–è¨“ç·´éç¨‹"""
        print("\nğŸ“Š ç¹ªè£½è¨“ç·´æ­·å²...")
        
        fig, axes = plt.subplots(1, 2, figsize=(15, 5))
        
        # æº–ç¢ºç‡æ›²ç·š
        axes[0].plot(self.history.history['accuracy'], label='è¨“ç·´æº–ç¢ºç‡', linewidth=2)
        axes[0].plot(self.history.history['val_accuracy'], label='é©—è­‰æº–ç¢ºç‡', linewidth=2)
        axes[0].set_title('æ¨¡å‹æº–ç¢ºç‡è®ŠåŒ–', fontsize=14, fontweight='bold')
        axes[0].set_xlabel('Epoch')
        axes[0].set_ylabel('æº–ç¢ºç‡')
        axes[0].legend()
        axes[0].grid(alpha=0.3)
        
        # æå¤±å‡½æ•¸æ›²ç·š
        axes[1].plot(self.history.history['loss'], label='è¨“ç·´æå¤±', linewidth=2)
        axes[1].plot(self.history.history['val_loss'], label='é©—è­‰æå¤±', linewidth=2)
        axes[1].set_title('æ¨¡å‹æå¤±è®ŠåŒ–', fontsize=14, fontweight='bold')
        axes[1].set_xlabel('Epoch')
        axes[1].set_ylabel('æå¤±å€¼')
        axes[1].legend()
        axes[1].grid(alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(f'{self.model_name}_training_history.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        print(f"âœ“ åœ–è¡¨å·²å„²å­˜ï¼š{self.model_name}_training_history.png")
    
    def evaluate(self):
        """è©•ä¼°æ¨¡å‹åœ¨é©—è­‰é›†ä¸Šçš„è¡¨ç¾"""
        print("\n" + "="*60)
        print("ğŸ“ˆ è©•ä¼°æ¨¡å‹è¡¨ç¾")
        print("="*60)
        
        # åœ¨é©—è­‰é›†ä¸Šè©•ä¼°
        val_loss, val_accuracy = self.model.evaluate(
            self.X_val, self.y_val_categorical, 
            verbose=0
        )
        
        print(f"\né©—è­‰é›†çµæœï¼š")
        print(f"  - æå¤±å€¼ï¼š{val_loss:.4f}")
        print(f"  - æº–ç¢ºç‡ï¼š{val_accuracy:.4f} ({val_accuracy*100:.2f}%)")
        
        # é æ¸¬
        y_pred_proba = self.model.predict(self.X_val, verbose=0)
        y_pred = np.argmax(y_pred_proba, axis=1)
        
        # åˆ†é¡å ±å‘Š
        print(f"\nğŸ“Š è©³ç´°åˆ†é¡å ±å‘Šï¼š")
        print(classification_report(self.y_val, y_pred, 
                                   target_names=[str(i) for i in range(10)]))
        
        return val_accuracy, y_pred
    
    def plot_confusion_matrix(self, y_pred):
        """ç¹ªè£½æ··æ·†çŸ©é™£"""
        print("\nğŸ¨ ç¹ªè£½æ··æ·†çŸ©é™£...")
        
        # è¨ˆç®—æ··æ·†çŸ©é™£
        cm = confusion_matrix(self.y_val, y_pred)
        
        # ç¹ªè£½
        fig, axes = plt.subplots(1, 2, figsize=(16, 6))
        
        # åŸå§‹è¨ˆæ•¸
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0],
                   xticklabels=range(10), yticklabels=range(10))
        axes[0].set_title('æ··æ·†çŸ©é™£ï¼ˆçµ•å°æ•¸é‡ï¼‰', fontsize=14, fontweight='bold')
        axes[0].set_xlabel('é æ¸¬æ¨™ç±¤')
        axes[0].set_ylabel('çœŸå¯¦æ¨™ç±¤')
        
        # æ­£è¦åŒ–ï¼ˆç™¾åˆ†æ¯”ï¼‰
        cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Blues', ax=axes[1],
                   xticklabels=range(10), yticklabels=range(10))
        axes[1].set_title('æ··æ·†çŸ©é™£ï¼ˆæ¯”ä¾‹ï¼‰', fontsize=14, fontweight='bold')
        axes[1].set_xlabel('é æ¸¬æ¨™ç±¤')
        axes[1].set_ylabel('çœŸå¯¦æ¨™ç±¤')
        
        plt.tight_layout()
        plt.savefig(f'{self.model_name}_confusion_matrix.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        # åˆ†ææœ€å®¹æ˜“æ··æ·†çš„æ•¸å­—å°
        print("\nğŸ” æœ€å®¹æ˜“æ··æ·†çš„æ•¸å­—å°ï¼ˆTop 5ï¼‰ï¼š")
        errors = []
        for i in range(10):
            for j in range(10):
                if i != j and cm[i][j] > 0:
                    errors.append((i, j, cm[i][j], cm_normalized[i][j]))
        
        errors.sort(key=lambda x: x[2], reverse=True)
        for rank, (true, pred, count, ratio) in enumerate(errors[:5], 1):
            print(f"  {rank}. çœŸå¯¦={true}, é æ¸¬={pred}: {count} æ¬¡ ({ratio:.2%})")
        
        print(f"\nâœ“ åœ–è¡¨å·²å„²å­˜ï¼š{self.model_name}_confusion_matrix.png")
    
    def visualize_predictions(self, num_samples=20):
        """è¦–è¦ºåŒ–é æ¸¬çµæœï¼ˆåŒ…å«éŒ¯èª¤æ¡ˆä¾‹ï¼‰"""
        print(f"\nğŸ–¼ï¸  è¦–è¦ºåŒ–é æ¸¬çµæœï¼ˆé¡¯ç¤º {num_samples} å€‹æ¨£æœ¬ï¼‰...")
        
        # éš¨æ©Ÿé¸æ“‡æ¨£æœ¬
        indices = np.random.choice(len(self.X_val), num_samples, replace=False)
        
        # é æ¸¬
        predictions = self.model.predict(self.X_val[indices], verbose=0)
        predicted_labels = np.argmax(predictions, axis=1)
        true_labels = self.y_val[indices]
        
        # ç¹ªåœ–
        rows = 4
        cols = 5
        fig, axes = plt.subplots(rows, cols, figsize=(15, 12))
        fig.suptitle('é æ¸¬çµæœè¦–è¦ºåŒ–ï¼ˆç¶ è‰²=æ­£ç¢ºï¼Œç´…è‰²=éŒ¯èª¤ï¼‰', 
                     fontsize=16, fontweight='bold')
        
        for idx, ax in enumerate(axes.flat):
            if idx < num_samples:
                image = self.X_val[indices[idx]].reshape(28, 28)
                true_label = true_labels[idx]
                pred_label = predicted_labels[idx]
                confidence = predictions[idx][pred_label] * 100
                
                ax.imshow(image, cmap='gray')
                
                # æ­£ç¢º=ç¶ è‰²ï¼ŒéŒ¯èª¤=ç´…è‰²
                color = 'green' if true_label == pred_label else 'red'
                ax.set_title(f'çœŸå¯¦:{true_label} é æ¸¬:{pred_label}\nä¿¡å¿ƒåº¦:{confidence:.1f}%',
                           color=color, fontsize=10)
                ax.axis('off')
            else:
                ax.axis('off')
        
        plt.tight_layout()
        plt.savefig(f'{self.model_name}_predictions.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        print(f"âœ“ åœ–è¡¨å·²å„²å­˜ï¼š{self.model_name}_predictions.png")
    
    def predict_test_set(self, output_path='submission.csv'):
        """é æ¸¬æ¸¬è©¦é›†ä¸¦ç”¢ç”Ÿ Kaggle æäº¤æª”æ¡ˆ"""
        print("\n" + "="*60)
        print("ğŸ¯ é æ¸¬æ¸¬è©¦é›†")
        print("="*60)
        
        # é æ¸¬
        print("æ­£åœ¨é æ¸¬...")
        test_predictions = self.model.predict(self.X_test, verbose=1)
        test_labels = np.argmax(test_predictions, axis=1)
        
        # ç”¢ç”Ÿæäº¤æª”æ¡ˆ
        submission = pd.DataFrame({
            'ImageId': range(1, len(test_labels) + 1),
            'Label': test_labels
        })
        
        submission.to_csv(output_path, index=False)
        
        print(f"\nâœ“ é æ¸¬å®Œæˆï¼")
        print(f"âœ“ æäº¤æª”æ¡ˆå·²å„²å­˜ï¼š{output_path}")
        print(f"âœ“ ç¸½å…±é æ¸¬ï¼š{len(test_labels)} ç­†è³‡æ–™")
        print(f"\né æ¸¬æ¨™ç±¤åˆ†ä½ˆï¼š")
        print(pd.Series(test_labels).value_counts().sort_index())
        
        return submission
    
    def save_model(self, filepath=None):
        """å„²å­˜æ¨¡å‹"""
        if filepath is None:
            filepath = f'{self.model_name}_final.keras'
        
        self.model.save(filepath)
        print(f"\nğŸ’¾ æ¨¡å‹å·²å„²å­˜ï¼š{filepath}")


# ==================== ä¸»ç¨‹å¼ ====================
if __name__ == "__main__":
    print("="*60)
    print("ğŸ¯ MNIST CNN è¨“ç·´å®Œæ•´æµç¨‹")
    print("="*60)
    
    # 1. åˆå§‹åŒ–è¨“ç·´å™¨
    trainer = MNISTCNNTrainer(model_name="MNIST_CNN_Standard")
    
    # 2. è¼‰å…¥è³‡æ–™
    trainer.load_preprocessed_data()
    
    # 3. å»ºç«‹æ¨¡å‹ï¼ˆå¯é¸æ“‡ï¼š'standard', 'deep', 'lightweight'ï¼‰
    trainer.build_cnn_model(architecture='standard')
    
    # 4. ç·¨è­¯æ¨¡å‹
    trainer.compile_model(learning_rate=0.001)
    
    # 5. è¨“ç·´æ¨¡å‹
    history = trainer.train(
        epochs=20,
        batch_size=128,
        use_callbacks=True
    )
    
    # 6. è¦–è¦ºåŒ–è¨“ç·´éç¨‹
    trainer.plot_training_history()
    
    # 7. è©•ä¼°æ¨¡å‹
    val_accuracy, y_pred = trainer.evaluate()
    
    # 8. ç¹ªè£½æ··æ·†çŸ©é™£
    trainer.plot_confusion_matrix(y_pred)
    
    # 9. è¦–è¦ºåŒ–é æ¸¬çµæœ
    trainer.visualize_predictions(num_samples=20)
    
    # 10. é æ¸¬æ¸¬è©¦é›†ä¸¦ç”¢ç”Ÿæäº¤æª”æ¡ˆ
    submission = trainer.predict_test_set(output_path='submission.csv')
    
    # 11. å„²å­˜æ¨¡å‹
    trainer.save_model()
    
    print("\n" + "="*60)
    print("âœ… æ‰€æœ‰æµç¨‹å®Œæˆï¼")
    print("="*60)
    print("\nç”¢ç”Ÿçš„æª”æ¡ˆï¼š")
    print("  ğŸ“Š MNIST_CNN_Standard_training_history.png")
    print("  ğŸ“Š MNIST_CNN_Standard_confusion_matrix.png")
    print("  ğŸ“Š MNIST_CNN_Standard_predictions.png")
    print("  ğŸ’¾ MNIST_CNN_Standard_best.keras")
    print("  ğŸ’¾ MNIST_CNN_Standard_final.keras")
    print("  ğŸ“„ submission.csv")
    print("="*60)
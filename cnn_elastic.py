import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models, callbacks
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import pandas as pd
from datetime import datetime
from sklearn.metrics import accuracy_score
from scipy.ndimage import gaussian_filter, map_coordinates

# è¨­å®šéš¨æ©Ÿç¨®å­
np.random.seed(42)
tf.random.set_seed(42)

class MNISTCNNWithElasticTTA:
    """MNIST CNN è¨“ç·´å™¨ with Elastic Transform + TTA"""
    
    def __init__(self, model_name="MNIST_CNN_Elastic_TTA"):
        """åˆå§‹åŒ–è¨“ç·´å™¨"""
        self.model_name = model_name
        self.model = None
        self.history = None
        
    def elastic_transform(self, image, alpha=36, sigma=4, random_state=None):
        """
        å½ˆæ€§è®Šå½¢ (Elastic Transform)
        
        Parameters:
        -----------
        image : ndarray
            è¼¸å…¥å½±åƒ (28, 28, 1)
        alpha : float
            è®Šå½¢å¼·åº¦ï¼ˆæ•¸å€¼è¶Šå¤§è®Šå½¢è¶Šæ˜é¡¯ï¼‰
        sigma : float
            å¹³æ»‘ç¨‹åº¦ï¼ˆé«˜æ–¯æ¿¾æ³¢çš„æ¨™æº–å·®ï¼‰
        random_state : int
            éš¨æ©Ÿç¨®å­
            
        Returns:
        --------
        è®Šå½¢å¾Œçš„å½±åƒ
        
        åŸç†ï¼š
        1. ç”Ÿæˆéš¨æ©Ÿä½ç§»å ´ï¼ˆæ¯å€‹åƒç´ å¾€å“ªå€‹æ–¹å‘ç§»å‹•ï¼‰
        2. ç”¨é«˜æ–¯æ¿¾æ³¢å¹³æ»‘ä½ç§»å ´ï¼ˆè®“è®Šå½¢çœ‹èµ·ä¾†è‡ªç„¶ï¼‰
        3. æ ¹æ“šä½ç§»å ´é‡æ–°æ˜ å°„åƒç´ ä½ç½®
        """
        if random_state is None:
            random_state = np.random.RandomState(None)
        
        shape = image.shape[:2]  # (28, 28)
        
        # ç”Ÿæˆéš¨æ©Ÿä½ç§»å ´
        dx = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma) * alpha
        dy = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma) * alpha
        
        # ç”Ÿæˆåº§æ¨™ç¶²æ ¼
        x, y = np.meshgrid(np.arange(shape[1]), np.arange(shape[0]))
        indices = np.reshape(y + dy, (-1, 1)), np.reshape(x + dx, (-1, 1))
        
        # æ‡‰ç”¨è®Šå½¢ï¼ˆå°æ¯å€‹é€šé“ï¼‰
        if len(image.shape) == 3:
            distorted_image = np.zeros_like(image)
            for i in range(image.shape[2]):
                distorted_image[:, :, i] = map_coordinates(
                    image[:, :, i], indices, order=1, mode='reflect'
                ).reshape(shape)
        else:
            distorted_image = map_coordinates(
                image, indices, order=1, mode='reflect'
            ).reshape(shape)
            
        return distorted_image
    
    def load_preprocessed_data(self):
        """è¼‰å…¥å·²å‰è™•ç†çš„è³‡æ–™"""
        print("ğŸ“‚ è¼‰å…¥å‰è™•ç†è³‡æ–™...")
        
        self.X_train = np.load('X_train.npy')
        self.X_val = np.load('X_val.npy')
        self.y_train = np.load('y_train.npy')
        self.y_val = np.load('y_val.npy')
        self.X_test = np.load('X_test.npy')
        
        print(f"âœ“ è³‡æ–™è¼‰å…¥å®Œæˆ")
        print(f"  X_train: {self.X_train.shape}")
        print(f"  X_val: {self.X_val.shape}")
        print(f"  X_test: {self.X_test.shape}")
        
        # è½‰æ›æ¨™ç±¤ç‚º One-Hot Encoding
        self.y_train_categorical = to_categorical(self.y_train, 10)
        self.y_val_categorical = to_categorical(self.y_val, 10)
        
        print(f"âœ“ æ¨™ç±¤è½‰æ›å®Œæˆï¼ˆOne-Hot Encodingï¼‰")
        
    def create_elastic_augmentation_generator(self, X, y, batch_size=64):
        """
        å»ºç«‹åŒ…å« Elastic Transform çš„è³‡æ–™ç”Ÿæˆå™¨
        
        é€™å€‹ç”Ÿæˆå™¨æœƒï¼š
        1. å…ˆåšåŸºç¤å¢å¼·ï¼ˆæ—‹è½‰ã€å¹³ç§»ç­‰ï¼‰
        2. ç„¶å¾Œæœ‰ 50% æ©Ÿç‡åš Elastic Transform
        """
        # åŸºç¤å¢å¼·
        datagen = ImageDataGenerator(
            rotation_range=15,
            width_shift_range=0.15,
            height_shift_range=0.15,
            zoom_range=0.15,
            shear_range=0.15,
            fill_mode='nearest'
        )
        
        # ç”ŸæˆåŸºç¤å¢å¼·çš„è³‡æ–™
        generator = datagen.flow(X, y, batch_size=batch_size)
        
        while True:
            # å–å¾—ä¸€å€‹ batch
            X_batch, y_batch = next(generator)
            
            # å° batch ä¸­çš„æ¯å¼µåœ–ç‰‡ï¼Œæœ‰ 50% æ©Ÿç‡åš Elastic Transform
            X_elastic = np.zeros_like(X_batch)
            for i in range(len(X_batch)):
                if np.random.random() > 0.5:
                    # åš Elastic Transform
                    X_elastic[i] = self.elastic_transform(
                        X_batch[i],
                        alpha=36,
                        sigma=4
                    )
                else:
                    # ä¸åšè®Šå½¢
                    X_elastic[i] = X_batch[i]
            
            yield X_elastic, y_batch
    
    def build_improved_cnn(self):
        """å»ºç«‹æ”¹é€²ç‰ˆ CNNï¼ˆåŠ å…¥ BatchNormalizationï¼‰"""
        print(f"\nğŸ—ï¸  å»ºç«‹æ”¹é€²ç‰ˆ CNN æ¨¡å‹...")
        
        model = models.Sequential([
            # Block 1
            layers.Conv2D(32, (3, 3), padding='same', input_shape=(28, 28, 1)),
            layers.BatchNormalization(),
            layers.Activation('relu'),
            layers.Conv2D(32, (3, 3), padding='same'),
            layers.BatchNormalization(),
            layers.Activation('relu'),
            layers.MaxPooling2D((2, 2)),
            layers.Dropout(0.25),
            
            # Block 2
            layers.Conv2D(64, (3, 3), padding='same'),
            layers.BatchNormalization(),
            layers.Activation('relu'),
            layers.Conv2D(64, (3, 3), padding='same'),
            layers.BatchNormalization(),
            layers.Activation('relu'),
            layers.MaxPooling2D((2, 2)),
            layers.Dropout(0.25),
            
            # Block 3
            layers.Conv2D(128, (3, 3), padding='same'),
            layers.BatchNormalization(),
            layers.Activation('relu'),
            layers.MaxPooling2D((2, 2)),
            layers.Dropout(0.25),
            
            # Dense layers
            layers.Flatten(),
            layers.Dense(256, activation='relu'),
            layers.BatchNormalization(),
            layers.Dropout(0.5),
            layers.Dense(128, activation='relu'),
            layers.BatchNormalization(),
            layers.Dropout(0.5),
            layers.Dense(10, activation='softmax')
        ], name='Improved_CNN_Elastic')
        
        self.model = model
        
        # é¡¯ç¤ºæ¨¡å‹æ¶æ§‹
        print("\nğŸ“Š æ¨¡å‹æ¶æ§‹æ‘˜è¦ï¼š")
        model.summary()
        
        trainable_params = np.sum([np.prod(v.shape) for v in model.trainable_weights])
        print(f"\nâœ“ å¯è¨“ç·´åƒæ•¸æ•¸é‡ï¼š{trainable_params:,}")
        
        return model
    
    def compile_model(self, learning_rate=0.001):
        """ç·¨è­¯æ¨¡å‹"""
        print(f"\nâš™ï¸  ç·¨è­¯æ¨¡å‹ï¼ˆå­¸ç¿’ç‡ï¼š{learning_rate}ï¼‰...")
        
        self.model.compile(
            optimizer=keras.optimizers.Adam(learning_rate=learning_rate),
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        print("âœ“ æ¨¡å‹ç·¨è­¯å®Œæˆ")
    
    def train_with_elastic_augmentation(self, epochs=35, batch_size=64):
        """ä½¿ç”¨ Elastic Transform è¨“ç·´æ¨¡å‹"""
        print("\n" + "="*60)
        print("ğŸš€ é–‹å§‹è¨“ç·´æ¨¡å‹ï¼ˆä½¿ç”¨ Elastic Transformï¼‰")
        print("="*60)
        print(f"è¨“ç·´åƒæ•¸ï¼š")
        print(f"  - Epochs: {epochs}")
        print(f"  - Batch Size: {batch_size}")
        print(f"  - è¨“ç·´æ¨£æœ¬æ•¸: {len(self.X_train)}")
        print(f"  - é©—è­‰æ¨£æœ¬æ•¸: {len(self.X_val)}")
        print(f"  - ä½¿ç”¨å¢å¼·ï¼šæ—‹è½‰ã€å¹³ç§»ã€ç¸®æ”¾ã€å‰ªåˆ‡ + Elastic Transform")
        print("="*60)
        
        # è¨­å®šå›èª¿å‡½æ•¸
        early_stopping = callbacks.EarlyStopping(
            monitor='val_loss',
            patience=8,
            restore_best_weights=True,
            verbose=1
        )
        
        checkpoint = callbacks.ModelCheckpoint(
            f'{self.model_name}_best.keras',
            monitor='val_accuracy',
            save_best_only=True,
            verbose=1
        )
        
        reduce_lr = callbacks.ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.5,
            patience=4,
            min_lr=1e-7,
            verbose=1
        )
        
        # å»ºç«‹åŒ…å« Elastic Transform çš„ç”Ÿæˆå™¨
        train_generator = self.create_elastic_augmentation_generator(
            self.X_train, 
            self.y_train_categorical,
            batch_size=batch_size
        )
        
        # è¨“ç·´
        start_time = datetime.now()
        
        self.history = self.model.fit(
            train_generator,
            steps_per_epoch=len(self.X_train) // batch_size,
            epochs=epochs,
            validation_data=(self.X_val, self.y_val_categorical),
            callbacks=[early_stopping, checkpoint, reduce_lr],
            verbose=1
        )
        
        end_time = datetime.now()
        training_time = (end_time - start_time).total_seconds()
        
        print("\n" + "="*60)
        print(f"âœ… è¨“ç·´å®Œæˆï¼ç¸½è€—æ™‚ï¼š{training_time:.2f} ç§’")
        print("="*60)
        
        return self.history
    
    def evaluate_on_validation(self):
        """åœ¨é©—è­‰é›†ä¸Šè©•ä¼°ï¼ˆç„¡ TTAï¼‰"""
        print("\nğŸ“ˆ è©•ä¼°æ¨¡å‹è¡¨ç¾ï¼ˆé©—è­‰é›†ï¼Œç„¡ TTAï¼‰...")
        
        val_loss, val_accuracy = self.model.evaluate(
            self.X_val, self.y_val_categorical, 
            verbose=0
        )
        
        print(f"é©—è­‰é›†æº–ç¢ºç‡ï¼ˆç„¡ TTAï¼‰ï¼š{val_accuracy:.4f} ({val_accuracy*100:.2f}%)")
        
        return val_accuracy
    
    def predict_with_tta(self, X, n_augmentations=10):
        """
        ä½¿ç”¨ Test Time Augmentation é€²è¡Œé æ¸¬
        
        åŒ…å«ï¼šåŸºç¤å¢å¼· + Elastic Transform
        """
        print(f"\nğŸ”® ä½¿ç”¨ TTA é€²è¡Œé æ¸¬ï¼ˆæ¯å¼µåœ–ç‰‡ {n_augmentations} æ¬¡å¢å¼·ï¼‰...")
        
        # åŸå§‹é æ¸¬
        predictions = self.model.predict(X, verbose=0)
        
        # å»ºç«‹ TTA ç”Ÿæˆå™¨
        tta_datagen = ImageDataGenerator(
            rotation_range=10,
            width_shift_range=0.1,
            height_shift_range=0.1,
            zoom_range=0.1,
            fill_mode='nearest'
        )
        
        # é€²è¡Œå¤šæ¬¡å¢å¼·é æ¸¬
        for i in range(n_augmentations - 1):
            # åŸºç¤å¢å¼·
            aug_generator = tta_datagen.flow(X, batch_size=len(X), shuffle=False)
            X_aug = next(aug_generator)
            
            # æœ‰ 50% æ©Ÿç‡é¡å¤–åš Elastic Transform
            if np.random.random() > 0.5:
                X_elastic = np.zeros_like(X_aug)
                for j in range(len(X_aug)):
                    X_elastic[j] = self.elastic_transform(X_aug[j], alpha=36, sigma=4)
                X_aug = X_elastic
            
            # é æ¸¬
            aug_predictions = self.model.predict(X_aug, verbose=0)
            
            # ç´¯åŠ 
            predictions += aug_predictions
            
            if (i + 1) % 3 == 0:
                print(f"  é€²åº¦ï¼š{i + 2}/{n_augmentations}")
        
        # å¹³å‡
        predictions = predictions / n_augmentations
        
        print(f"âœ“ TTA é æ¸¬å®Œæˆ")
        
        return predictions
    
    def evaluate_with_tta(self, n_augmentations=10):
        """åœ¨é©—è­‰é›†ä¸Šä½¿ç”¨ TTA è©•ä¼°"""
        print("\nğŸ“ˆ è©•ä¼°æ¨¡å‹è¡¨ç¾ï¼ˆé©—è­‰é›†ï¼Œä½¿ç”¨ TTA + Elasticï¼‰...")
        
        # ä½¿ç”¨ TTA é æ¸¬
        val_predictions = self.predict_with_tta(self.X_val, n_augmentations)
        val_pred_labels = np.argmax(val_predictions, axis=1)
        
        # è¨ˆç®—æº–ç¢ºç‡
        tta_accuracy = accuracy_score(self.y_val, val_pred_labels)
        
        print(f"é©—è­‰é›†æº–ç¢ºç‡ï¼ˆTTA + Elasticï¼‰ï¼š{tta_accuracy:.4f} ({tta_accuracy*100:.2f}%)")
        
        # æ¯”è¼ƒæ”¹å–„
        no_tta_accuracy = self.evaluate_on_validation()
        improvement = (tta_accuracy - no_tta_accuracy) * 100
        print(f"\nâœ¨ TTA æ”¹å–„ï¼š+{improvement:.2f}%")
        
        return tta_accuracy
    
    def predict_test_set_with_tta(self, n_augmentations=12, output_path='submission_elastic_tta.csv'):
        """ä½¿ç”¨ TTA + Elastic Transform é æ¸¬æ¸¬è©¦é›†"""
        print("\n" + "="*60)
        print("ğŸ¯ é æ¸¬æ¸¬è©¦é›†ï¼ˆä½¿ç”¨ TTA + Elastic Transformï¼‰")
        print("="*60)
        
        # ä½¿ç”¨ TTA é æ¸¬
        test_predictions = self.predict_with_tta(self.X_test, n_augmentations)
        test_labels = np.argmax(test_predictions, axis=1)
        
        # ç”¢ç”Ÿæäº¤æª”æ¡ˆ
        submission = pd.DataFrame({
            'ImageId': range(1, len(test_labels) + 1),
            'Label': test_labels
        })
        
        submission.to_csv(output_path, index=False)
        
        print(f"\nâœ“ é æ¸¬å®Œæˆï¼")
        print(f"âœ“ æäº¤æª”æ¡ˆå·²å„²å­˜ï¼š{output_path}")
        print(f"âœ“ ç¸½å…±é æ¸¬ï¼š{len(test_labels)} ç­†è³‡æ–™")
        print(f"\né æ¸¬æ¨™ç±¤åˆ†ä½ˆï¼š")
        print(submission['Label'].value_counts().sort_index())
        
        return submission
    
    def save_model(self, filepath=None):
        """å„²å­˜æ¨¡å‹"""
        if filepath is None:
            filepath = f'{self.model_name}_final.keras'
        
        self.model.save(filepath)
        print(f"\nğŸ’¾ æ¨¡å‹å·²å„²å­˜ï¼š{filepath}")


# ==================== ä¸»ç¨‹å¼ ====================
if __name__ == "__main__":
    print("="*60)
    print("ğŸ¯ MNIST CNN + Elastic Transform + TTA")
    print("="*60)
    
    # 1. åˆå§‹åŒ–è¨“ç·´å™¨
    trainer = MNISTCNNWithElasticTTA(model_name="MNIST_CNN_Elastic_TTA")
    
    # 2. è¼‰å…¥è³‡æ–™
    trainer.load_preprocessed_data()
    
    # 3. å»ºç«‹æ”¹é€²ç‰ˆæ¨¡å‹
    trainer.build_improved_cnn()
    
    # 4. ç·¨è­¯æ¨¡å‹
    trainer.compile_model(learning_rate=0.001)
    
    # 5. è¨“ç·´æ¨¡å‹ï¼ˆä½¿ç”¨ Elastic Transformï¼‰
    print("\nğŸ’¡ è¨“ç·´æ™‚æœƒä½¿ç”¨ï¼š")
    print("   - æ—‹è½‰ Â±15Â°")
    print("   - å¹³ç§» Â±15%")
    print("   - ç¸®æ”¾ Â±15%")
    print("   - å‰ªåˆ‡è®Šå½¢")
    print("   - Elastic Transformï¼ˆ50% æ©Ÿç‡ï¼‰â† æ–°å¢ï¼")
    print("")
    
    history = trainer.train_with_elastic_augmentation(
        epochs=35,
        batch_size=64
    )
    
    # 6. è©•ä¼°æ¨¡å‹
    print("\n" + "="*60)
    print("ğŸ“Š æ¨¡å‹è©•ä¼°")
    print("="*60)
    
    # ç„¡ TTA çš„æº–ç¢ºç‡
    no_tta_acc = trainer.evaluate_on_validation()
    
    # ä½¿ç”¨ TTA + Elastic çš„æº–ç¢ºç‡
    tta_acc = trainer.evaluate_with_tta(n_augmentations=10)
    
    # 7. é æ¸¬æ¸¬è©¦é›†ï¼ˆä½¿ç”¨ TTA + Elasticï¼‰
    print("\n" + "="*60)
    print("ğŸš€ é–‹å§‹é æ¸¬æ¸¬è©¦é›†")
    print("="*60)
    
    submission = trainer.predict_test_set_with_tta(
        n_augmentations=12,  # å¯ä»¥èª¿æ•´ï¼ˆ10-15 éƒ½å¯ä»¥ï¼‰
        output_path='submission_elastic_tta.csv'
    )
    
    # 8. å„²å­˜æ¨¡å‹
    trainer.save_model()
    
    print("\n" + "="*60)
    print("âœ… æ‰€æœ‰æµç¨‹å®Œæˆï¼")
    print("="*60)
    print("\nç”¢ç”Ÿçš„æª”æ¡ˆï¼š")
    print("  ğŸ“„ submission_elastic_tta.csv  â† æäº¤é€™å€‹åˆ° Kaggle")
    print("  ğŸ’¾ MNIST_CNN_Elastic_TTA_best.keras")
    print("  ğŸ’¾ MNIST_CNN_Elastic_TTA_final.keras")
    print("="*60)
    print("\nğŸ¯ æ”¹é€²é‡é»ï¼š")
    print("  1. âœ… è¨“ç·´æ™‚åŠ å…¥ Elastic Transformï¼ˆæ¨¡æ“¬æ‰‹å¯«è®Šå½¢ï¼‰")
    print("  2. âœ… TTA æ™‚ä¹Ÿæœ‰æ©Ÿç‡ä½¿ç”¨ Elastic Transform")
    print("  3. âœ… é æœŸæå‡ï¼š0.99371 â†’ 0.996-0.998")
    print("="*60)
    print("\nğŸ’¡ å¦‚æœé‚„æƒ³æå‡ï¼š")
    print("  - å¢åŠ  n_augmentations åˆ° 15-20")
    print("  - è¨“ç·´æ›´å¤š epochsï¼ˆ40-50ï¼‰")
    print("  - æˆ–è€ƒæ…® Ensemble å¤šå€‹æ¨¡å‹")
    print("="*60)